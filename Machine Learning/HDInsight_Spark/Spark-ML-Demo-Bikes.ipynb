{"nbformat_minor": 2, "cells": [{"source": "## Bike Sharing Dataset\n\nData: This dataset contains bike rental info from 2011 and 2012 in Capital bikeshare system. [Source UCI Machine Learning Repo] (http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset)", "cell_type": "markdown", "metadata": {}}, {"execution_count": 8, "cell_type": "code", "source": "df = sqlContext.read.format('csv').option(\"header\", 'true').load(\"wasb://datasets@ocpdemostorageaccount.blob.core.windows.net/hour.csv\")\ndf.cache()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "DataFrame[instant: string, dteday: string, season: string, yr: string, mnth: string, hr: string, holiday: string, weekday: string, workingday: string, weathersit: string, temp: string, atemp: string, hum: string, windspeed: string, casual: string, registered: string, cnt: string]"}], "metadata": {"collapsed": false}}, {"source": "### DataSet info\n\n- instant: record index\n- dteday : date\n- season : season (1:springer, 2:summer, 3:fall, 4:winter)\n- yr : year (0: 2011, 1:2012)\n- mnth : month ( 1 to 12)\n- hr : hour (0 to 23)\n- holiday : weather day is holiday or not (extracted from [Web Link])\n- weekday : day of the week\n- workingday : if day is neither weekend nor holiday is 1, otherwise is 0.\n+ weathersit :\n- 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n- 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n- 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n- 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n- temp : Normalized temperature in Celsius. The values are derived via (t-t_min)/(t_max-t_min), t_min=-8, t_max=+39 (only in hourly scale)\n- atemp: Normalized feeling temperature in Celsius. The values are derived via (t-t_min)/(t_max-t_min), t_min=-16, t_max=+50 (only in hourly scale)\n- hum: Normalized humidity. The values are divided to 100 (max)\n- windspeed: Normalized wind speed. The values are divided to 67 (max)\n- casual: count of casual users\n- registered: count of registered users\n- cnt: count of total rental bikes including both casual and registered", "cell_type": "markdown", "metadata": {}}, {"execution_count": 10, "cell_type": "code", "source": "print \"Our dataset has %d rows.\" % df.count()\n", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Our dataset has 17379 rows."}], "metadata": {"collapsed": false}}, {"execution_count": 11, "cell_type": "code", "source": "df.show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+-------+----------+------+---+----+---+-------+-------+----------+----------+----+------+----+---------+------+----------+---+\n|instant|    dteday|season| yr|mnth| hr|holiday|weekday|workingday|weathersit|temp| atemp| hum|windspeed|casual|registered|cnt|\n+-------+----------+------+---+----+---+-------+-------+----------+----------+----+------+----+---------+------+----------+---+\n|      1|2011-01-01|     1|  0|   1|  0|      0|      6|         0|         1|0.24|0.2879|0.81|        0|     3|        13| 16|\n|      2|2011-01-01|     1|  0|   1|  1|      0|      6|         0|         1|0.22|0.2727| 0.8|        0|     8|        32| 40|\n|      3|2011-01-01|     1|  0|   1|  2|      0|      6|         0|         1|0.22|0.2727| 0.8|        0|     5|        27| 32|\n|      4|2011-01-01|     1|  0|   1|  3|      0|      6|         0|         1|0.24|0.2879|0.75|        0|     3|        10| 13|\n|      5|2011-01-01|     1|  0|   1|  4|      0|      6|         0|         1|0.24|0.2879|0.75|        0|     0|         1|  1|\n|      6|2011-01-01|     1|  0|   1|  5|      0|      6|         0|         2|0.24|0.2576|0.75|   0.0896|     0|         1|  1|\n|      7|2011-01-01|     1|  0|   1|  6|      0|      6|         0|         1|0.22|0.2727| 0.8|        0|     2|         0|  2|\n|      8|2011-01-01|     1|  0|   1|  7|      0|      6|         0|         1| 0.2|0.2576|0.86|        0|     1|         2|  3|\n|      9|2011-01-01|     1|  0|   1|  8|      0|      6|         0|         1|0.24|0.2879|0.75|        0|     1|         7|  8|\n|     10|2011-01-01|     1|  0|   1|  9|      0|      6|         0|         1|0.32|0.3485|0.76|        0|     8|         6| 14|\n|     11|2011-01-01|     1|  0|   1| 10|      0|      6|         0|         1|0.38|0.3939|0.76|   0.2537|    12|        24| 36|\n|     12|2011-01-01|     1|  0|   1| 11|      0|      6|         0|         1|0.36|0.3333|0.81|   0.2836|    26|        30| 56|\n|     13|2011-01-01|     1|  0|   1| 12|      0|      6|         0|         1|0.42|0.4242|0.77|   0.2836|    29|        55| 84|\n|     14|2011-01-01|     1|  0|   1| 13|      0|      6|         0|         2|0.46|0.4545|0.72|   0.2985|    47|        47| 94|\n|     15|2011-01-01|     1|  0|   1| 14|      0|      6|         0|         2|0.46|0.4545|0.72|   0.2836|    35|        71|106|\n|     16|2011-01-01|     1|  0|   1| 15|      0|      6|         0|         2|0.44|0.4394|0.77|   0.2985|    40|        70|110|\n|     17|2011-01-01|     1|  0|   1| 16|      0|      6|         0|         2|0.42|0.4242|0.82|   0.2985|    41|        52| 93|\n|     18|2011-01-01|     1|  0|   1| 17|      0|      6|         0|         2|0.44|0.4394|0.82|   0.2836|    15|        52| 67|\n|     19|2011-01-01|     1|  0|   1| 18|      0|      6|         0|         3|0.42|0.4242|0.88|   0.2537|     9|        26| 35|\n|     20|2011-01-01|     1|  0|   1| 19|      0|      6|         0|         3|0.42|0.4242|0.88|   0.2537|     6|        31| 37|\n+-------+----------+------+---+----+---+-------+-------+----------+----------+----+------+----+---------+------+----------+---+\nonly showing top 20 rows"}], "metadata": {"collapsed": false}}, {"source": "### Preprocess Data\n\nPredict: cnt\nCleaning:\n    - Remove casual, registered  as cnt is sum of these two\n    - dteday \n    - instant\n    ", "cell_type": "markdown", "metadata": {}}, {"execution_count": 12, "cell_type": "code", "source": "df = df.drop(\"instant\").drop(\"dteday\").drop(\"casual\").drop(\"registered\")\ndf.show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+------+---+----+---+-------+-------+----------+----------+----+------+----+---------+---+\n|season| yr|mnth| hr|holiday|weekday|workingday|weathersit|temp| atemp| hum|windspeed|cnt|\n+------+---+----+---+-------+-------+----------+----------+----+------+----+---------+---+\n|     1|  0|   1|  0|      0|      6|         0|         1|0.24|0.2879|0.81|        0| 16|\n|     1|  0|   1|  1|      0|      6|         0|         1|0.22|0.2727| 0.8|        0| 40|\n|     1|  0|   1|  2|      0|      6|         0|         1|0.22|0.2727| 0.8|        0| 32|\n|     1|  0|   1|  3|      0|      6|         0|         1|0.24|0.2879|0.75|        0| 13|\n|     1|  0|   1|  4|      0|      6|         0|         1|0.24|0.2879|0.75|        0|  1|\n|     1|  0|   1|  5|      0|      6|         0|         2|0.24|0.2576|0.75|   0.0896|  1|\n|     1|  0|   1|  6|      0|      6|         0|         1|0.22|0.2727| 0.8|        0|  2|\n|     1|  0|   1|  7|      0|      6|         0|         1| 0.2|0.2576|0.86|        0|  3|\n|     1|  0|   1|  8|      0|      6|         0|         1|0.24|0.2879|0.75|        0|  8|\n|     1|  0|   1|  9|      0|      6|         0|         1|0.32|0.3485|0.76|        0| 14|\n|     1|  0|   1| 10|      0|      6|         0|         1|0.38|0.3939|0.76|   0.2537| 36|\n|     1|  0|   1| 11|      0|      6|         0|         1|0.36|0.3333|0.81|   0.2836| 56|\n|     1|  0|   1| 12|      0|      6|         0|         1|0.42|0.4242|0.77|   0.2836| 84|\n|     1|  0|   1| 13|      0|      6|         0|         2|0.46|0.4545|0.72|   0.2985| 94|\n|     1|  0|   1| 14|      0|      6|         0|         2|0.46|0.4545|0.72|   0.2836|106|\n|     1|  0|   1| 15|      0|      6|         0|         2|0.44|0.4394|0.77|   0.2985|110|\n|     1|  0|   1| 16|      0|      6|         0|         2|0.42|0.4242|0.82|   0.2985| 93|\n|     1|  0|   1| 17|      0|      6|         0|         2|0.44|0.4394|0.82|   0.2836| 67|\n|     1|  0|   1| 18|      0|      6|         0|         3|0.42|0.4242|0.88|   0.2537| 35|\n|     1|  0|   1| 19|      0|      6|         0|         3|0.42|0.4242|0.88|   0.2537| 37|\n+------+---+----+---+-------+-------+----------+----------+----+------+----+---------+---+\nonly showing top 20 rows"}], "metadata": {"collapsed": false}}, {"execution_count": 13, "cell_type": "code", "source": "df.printSchema()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "root\n |-- season: string (nullable = true)\n |-- yr: string (nullable = true)\n |-- mnth: string (nullable = true)\n |-- hr: string (nullable = true)\n |-- holiday: string (nullable = true)\n |-- weekday: string (nullable = true)\n |-- workingday: string (nullable = true)\n |-- weathersit: string (nullable = true)\n |-- temp: string (nullable = true)\n |-- atemp: string (nullable = true)\n |-- hum: string (nullable = true)\n |-- windspeed: string (nullable = true)\n |-- cnt: string (nullable = true)"}], "metadata": {"collapsed": false}}, {"execution_count": 15, "cell_type": "code", "source": "#Converting all feils to double\n\nfrom pyspark.sql.functions import col  # for indicating a column using a string in the line below\ndf = df.select([col(c).cast(\"double\").alias(c) for c in df.columns])\ndf.printSchema()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "root\n |-- season: double (nullable = true)\n |-- yr: double (nullable = true)\n |-- mnth: double (nullable = true)\n |-- hr: double (nullable = true)\n |-- holiday: double (nullable = true)\n |-- weekday: double (nullable = true)\n |-- workingday: double (nullable = true)\n |-- weathersit: double (nullable = true)\n |-- temp: double (nullable = true)\n |-- atemp: double (nullable = true)\n |-- hum: double (nullable = true)\n |-- windspeed: double (nullable = true)\n |-- cnt: double (nullable = true)"}], "metadata": {"collapsed": false}}, {"execution_count": 17, "cell_type": "code", "source": "#Split data for training and testing\ntrain, test = df.randomSplit([0.7, 0.3])\nprint \"We have %d training examples and %d test examples.\" % (train.count(), test.count())", "outputs": [{"output_type": "stream", "name": "stdout", "text": "We have 12040 training examples and 5339 test examples."}], "metadata": {"collapsed": false}}, {"execution_count": 18, "cell_type": "code", "source": "#Using Grandient boosting trees (GBT) for prediction\n# Features\n#    yr, season, holiday, workingday, weathersit\n\nfrom pyspark.ml.feature import VectorAssembler, VectorIndexer\nfeaturesCols = df.columns\nfeaturesCols.remove('cnt')\n#Concat all cols into single column\nvectorAssembler = VectorAssembler(inputCols=featuresCols, outputCol=\"rawFeatures\")\n# This identifies categorical features and indexes them.\nvectorIndexer = VectorIndexer(inputCol=\"rawFeatures\", outputCol=\"features\", maxCategories=4)", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 19, "cell_type": "code", "source": "from pyspark.ml.regression import GBTRegressor\ngbt = GBTRegressor(labelCol=\"cnt\")", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": 20, "cell_type": "code", "source": "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom pyspark.ml.evaluation import RegressionEvaluator\n#  - maxDepth: max depth of each decision tree  \n#  - maxIter: iterations, i.e., number of trees in each GBT \nparamGrid = ParamGridBuilder()\\\n  .addGrid(gbt.maxDepth, [2, 5])\\\n  .addGrid(gbt.maxIter, [10, 100])\\\n  .build()\nevaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=gbt.getLabelCol(), predictionCol=gbt.getPredictionCol())\n# Declare the CrossValidator, which runs model tuning\ncv = CrossValidator(estimator=gbt, evaluator=evaluator, estimatorParamMaps=paramGrid)", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "from pyspark.ml import Pipeline\npipeline = Pipeline(stages=[vectorAssembler, vectorIndexer, cv])\npipelineModel = pipeline.fit(train)\npredictions = pipelineModel.transform(test)\npredictions.select(\"cnt\", \"prediction\", *featuresCols).show()", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "rmse = evaluator.evaluate(predictions)\nprint \"RMSE on our test set: %g\" % rmse", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "Plot predictions against hr ", "outputs": [], "metadata": {"collapsed": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "PySpark", "name": "pysparkkernel", "language": ""}, "language_info": {"mimetype": "text/x-python", "pygments_lexer": "python2", "name": "pyspark", "codemirror_mode": {"version": 2, "name": "python"}}}}